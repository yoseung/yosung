{
  
    
        "post0": {
            "title": "2-2",
            "content": "&#54408;&#51333; &#50696;&#52769;&#54616;&#44592; . # +)파라미터: 소트웨어나 시스템상의 작동에 영향을 미치며, 외부로부터 투입되는 데이터 . conda install scikit-learn !pip install pandas import pandas as pd pip install scikit-learn . import sklearn print(sklearn.__version__) . 1.0.2 . from sklearn.datasets import load_iris #알고리즘 구현(의사결정트리) from sklearn.tree import DecisionTreeClassifier #학습 데이터와 테스트 데이터 분리 from sklearn.model_selection import train_test_split . iris=load_iris() #피쳐:: 길이나 너비 iris_data=iris.data #레이블:: 품종 iris_label=iris.target iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names) iris_df[&#39;label&#39;]=iris.target . X_train, X_test, y_train, y_test=train_test_split(iris_data, iris_label, test_size=0.2, random_state=11) #위 처럼 학습데이터 확보후 의사결정 트리 이용하기(객체?) dt_clf=DecisionTreeClassifier(random_state=11) #선학습 dt_clf.fit(X_train, y_train) #후예측 pred=dt_clf.predict(X_test) #예측 결과 from sklearn.metrics import accuracy_score print(&#39;정확도: {0:4f}&#39;.format(accuracy_score(y_train, pred))) print(&#39;정확도: {0:4f}&#39;.format(accuracy_score(y_test, pred))) . ValueError Traceback (most recent call last) Input In [39], in &lt;cell line: 11&gt;() 9 #예측 결과 10 from sklearn.metrics import accuracy_score &gt; 11 print(&#39;정확도: {0:4f}&#39;.format(accuracy_score(y_train, pred))) 12 print(&#39;정확도: {0:4f}&#39;.format(accuracy_score(y_test, pred))) File ~ anaconda3 envs py39 lib site-packages sklearn metrics _classification.py:211, in accuracy_score(y_true, y_pred, normalize, sample_weight) 145 &#34;&#34;&#34;Accuracy classification score. 146 147 In multilabel classification, this function computes subset accuracy: (...) 207 0.5 208 &#34;&#34;&#34; 210 # Compute accuracy for each possible representation --&gt; 211 y_type, y_true, y_pred = _check_targets(y_true, y_pred) 212 check_consistent_length(y_true, y_pred, sample_weight) 213 if y_type.startswith(&#34;multilabel&#34;): File ~ anaconda3 envs py39 lib site-packages sklearn metrics _classification.py:84, in _check_targets(y_true, y_pred) 57 def _check_targets(y_true, y_pred): 58 &#34;&#34;&#34;Check that y_true and y_pred belong to the same classification task. 59 60 This converts multiclass or binary types to a common shape, and raises a (...) 82 y_pred : array or indicator matrix 83 &#34;&#34;&#34; &gt; 84 check_consistent_length(y_true, y_pred) 85 type_true = type_of_target(y_true) 86 type_pred = type_of_target(y_pred) File ~ anaconda3 envs py39 lib site-packages sklearn utils validation.py:332, in check_consistent_length(*arrays) 330 uniques = np.unique(lengths) 331 if len(uniques) &gt; 1: --&gt; 332 raise ValueError( 333 &#34;Found input variables with inconsistent numbers of samples: %r&#34; 334 % [int(l) for l in lengths] 335 ) ValueError: Found input variables with inconsistent numbers of samples: [120, 30] .",
            "url": "https://yoseung.github.io/yosung/python/2022/05/08/Untitled5.html",
            "relUrl": "/python/2022/05/08/Untitled5.html",
            "date": " • May 8, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "5. &#45936;&#51060;&#53552;&#51032; &#51204;&#52376;&#47532; . 결손값(NaN, Null)을 변환해줘야 함. | 그러나 상황에 따라 피처값중 Null값이 얼마 없다면 피처값의 평균값으로 대체할 수 있지만 Null이 대부분이라면 해당 피처는 드랍하는게 낫다. | . +) 사이킷런의 머신러닝 알고리즘은 문자열을 입력값으로 허용하지 않아 숫자형으로 변환되야함. 문자열 피처에는 일반적으로 카테고리형과 텍스트형이 있음. 텍스트형은 피처 벡터화를 해주거나 불필요하다면 삭제하는게 좋음. 불필요 경우로는 주민번호나 단순 문자가 있는데 이런 식별자 피처는 데이터 로우를 식별하는 용도로 사용되어 예측에 중요한 요소가 아님. 그래서 알고리즘을 오히려 복잡하게 만들고 예측 성능을 저하시켜 삭제하는게 좋음 . &#45936;&#51060;&#53552; &#51064;&#53076;&#46377; . 인코딩 방식에는 레이블 인코딩과 원핫 인코딩이 있음 . 레이블 인코딩: . 문자열 값을 숫자영 카테고리 값으로 변환하는 방식. 예를들어 TV:1, 냉장고:2 주의할 점은 &#39;01&#39;, &#39;02&#39;와 같은 코드 값 역시 문자열이므로 1, 2와 같은 숫자형 값으로 변환돼야 함. 위에서 말하듯 사이킷런의 머신러닝 알고리즘은 문자열을 값을 허용안해 숫자형으로 바꿔야함. | 사이킷런의 레이블 인코딩은 LabelEncoder 클래스로 구현함. | . | . from sklearn.preprocessing import LabelEncoder items=[&#39;TV&#39;, &#39;냉장고&#39;, &#39;전자레인지&#39;, &#39;컴퓨터&#39;, &#39;선풍기&#39;, &#39;선풍기&#39;, &#39;믹서&#39;, &#39;믹서&#39;] #LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩 수행. encoder=LabelEncoder() encoder.fit(items) labels=encoder.transform(items) print(&#39;인코딩 변환값:&#39;, labels) . 인코딩 변환값: [0 1 4 5 3 3 2 2] . +) 메서드 fit()의 역할이 많은데 우선 지도학습에서 특정 레이블을 예측하기 전에 데이를 학습시키기 위해 사용, 데이터 전처리 과정에서 사이킷런을 통해 데이터를 변환하는 대부분의 로직에서 fit은 transform과 함께 사용됨. fit()은 학습 데이터 세트에서 변환을 위한 기반을 설정하는 단계이고, transform()은 fit()에서 저장한 설정값들을 기반으로 데이터를 변환하는 메세드임. . +) fit_transform()은 training data에만 사용되고 왜 transfrom은 test data에만 사용하는 됨. test data는 모델이 학습된 후에 평가할 때만 사용되어야 하는데 fit_transform을 test data에도 하게 된다면 모델의 성능을 평가할 수 없기 때문. . print(&#39;인코딩 클래스&#39;,encoder.classes_) . 인코딩 클래스 [&#39;TV&#39; &#39;냉장고&#39; &#39;믹서&#39; &#39;선풍기&#39; &#39;전자레인지&#39; &#39;컴퓨터&#39;] . #질문: 가나다 순임?? print(&#39;디코딩 원본값:&#39;, encoder.inverse_transform([4,5,1,1,0,2,3])) . 디코딩 원본값: [&#39;전자레인지&#39; &#39;컴퓨터&#39; &#39;냉장고&#39; &#39;냉장고&#39; &#39;TV&#39; &#39;믹서&#39; &#39;선풍기&#39;] . 원핫 인코딩: . 나와있는 피처만큼 행 만들고 해당 행에서 고유값을 나타내는 칼럼에만 1, 나머지는 0을 표시. 기존의 행으로 구성되 있는것을 열형태로 변환해주는 것임. 칼럼이란게 레이블 종류임. | 숫자는 크고 작음에 대한 특성이 있어 레이블 인코딩시 몇몇 ml알고리즘에서 가중치가 더 부여되거나 더 중요하게 인식할 가능성으로 예측 성능이 떨어질수 있음. (트리 게열 ml알고리즘 제외:: 숫자의 특성 비교 안해서) 이러한 레이블 인코딩의 단점을 보완한게 원핫 코딩 | . | . from sklearn.preprocessing import OneHotEncoder import numpy as np items=[&#39;TV&#39;, &#39;냉장고&#39;, &#39;전자레인지&#39;, &#39;컴퓨터&#39;, &#39;선풍기&#39;, &#39;선풍기&#39;, &#39;믹서&#39;, &#39;믹서&#39;] #먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환합니다. encoder=LabelEncoder() encoder.fit(items) labels=encoder.transform(items) #2차 데이터로 변환합니다. labels=labels.reshape(-1,1) #원-핫 인코딩을 적용합니다. oh_encoder=OneHotEncoder() oh_encoder.fit(labels) oh_labels=oh_encoder.transform(labels) print(&#39;원-핫 인코딩 데이터&#39;) print(oh_labels.toarray()) print(&#39;원-핫 인코딩 데이터 차원&#39;) print(oh_labels.shape) #위의 결과를 통해 8개의 레코드와 1개의 칼럼을 가진 원본 데이터가 8개의 레코드와 6개의 칼럼으로 가진 데이터로 변환됨. #oh_labels이 sparse matrix이므로, 내용을 보기위해서 toarray() 메서드 사용 . 원-핫 인코딩 데이터 [[1. 0. 0. 0. 0. 0.] [0. 1. 0. 0. 0. 0.] [0. 0. 0. 0. 1. 0.] [0. 0. 0. 0. 0. 1.] [0. 0. 0. 1. 0. 0.] [0. 0. 0. 1. 0. 0.] [0. 0. 1. 0. 0. 0.] [0. 0. 1. 0. 0. 0.]] 원-핫 인코딩 데이터 차원 (8, 6) . oh_labels . &lt;8x6 sparse matrix of type &#39;&lt;class &#39;numpy.float64&#39;&gt;&#39; with 8 stored elements in Compressed Sparse Row format&gt; . #인식할 가능성으로 예측 성능이 떨어질수 있다고 했는데 그럼, 원-핫 인코딩 전에 레이블 인코딩해도 성능이 떨어지는 것은 아닌지? . import pandas as pd df=pd.DataFrame({&#39;item&#39;:[&#39;TV&#39;, &#39;냉장고&#39;, &#39;전자레인지&#39;, &#39;컴퓨터&#39;, &#39;선풍기&#39;, &#39;선풍기&#39;, &#39;믹서&#39;, &#39;믹서&#39;]}) df . item . 0 TV | . 1 냉장고 | . 2 전자레인지 | . 3 컴퓨터 | . 4 선풍기 | . 5 선풍기 | . 6 믹서 | . 7 믹서 | . pd.get_dummies(df) . item_TV item_냉장고 item_믹서 item_선풍기 item_전자레인지 item_컴퓨터 . 0 1 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 1 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 1 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 1 | . 4 0 | 0 | 0 | 1 | 0 | 0 | . 5 0 | 0 | 0 | 1 | 0 | 0 | . 6 0 | 0 | 1 | 0 | 0 | 0 | . 7 0 | 0 | 1 | 0 | 0 | 0 | . &#54588;&#52376; &#49828;&#52992;&#51068;&#47553;&#44284; &#51221;&#44508;&#54868; . 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업을 피처 스케일링 이라고 한다. 대표적인 방법으로 표준화와 정규화가 있다. 표준화는 데이터의 피처 각각 평균이 0이고 분산이 1인 가우시안 정규분포를 가진 값으로 변환하는 것을 의미. 정규화는 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해 주는 것임. 0~1사이의 값으로. 속도와 거리로 서로 다른 피처의 크기를 통일하기 위해 0~1 사이의 값으로 변환함. 참고로 아래의 xi_new는 모두 다른 의미임. | . [피처 스케일링] -일반적인 표준화: xi_new=(xi-mean(x))/stdev(x) -정규화: xi_new=(xi-min(x))/(max(x)-min(x)) . [벡터 정규화] -사이킷런에서 선형대수의 정규화 (피처가 세개일때): xi_new=xi/((xi^2+yi^2+zi^2)^0.5) . 정규화가 저거 뜻하는거 맞겠지? | . StandardScaler . 표준화를 쉽게 지원하기 위한 클래스임. 각각의 피처를 평균이 0이고 분산이 1인 값으로 변환해줌(가우시안 정규분포) | . +) 사이킷런에서 구현한 RBF 커널을 이용하는 서포트 벡트 머신이나 선형 회귀, 로지스틱 회귀는 데이터가 가우시안 분포를 가지고 있다고 가정하고 구현됬기에 사전에 표준화를 적용하는 것이 예측 성능 향상에 중요한 요소가 될수 있음. . from sklearn.datasets import load_iris import pandas as pd #붓꽆 데이터 세트를 로딩하고 DataFrame으로 변환합니다. iris=load_iris() iris_data=iris.data iris_df=pd.DataFrame(data=iris_data, columns=iris.feature_names) print(&#39;feature 들의 평균 값&#39;) print(iris_df.mean()) print(&#39; nfeature 들의 분산 값&#39;) print(iris_df.var()) #var이 분산을 나타내는 약어 . feature 들의 평균 값 sepal length (cm) 5.843333 sepal width (cm) 3.057333 petal length (cm) 3.758000 petal width (cm) 1.199333 dtype: float64 feature 들의 분산 값 sepal length (cm) 0.685694 sepal width (cm) 0.189979 petal length (cm) 3.116278 petal width (cm) 0.581006 dtype: float64 . from sklearn.preprocessing import StandardScaler #StandardScaler객체 생성 scaler=StandardScaler() #StandardScaler로 데이터 세트 변환. fit()과 transform() 호출 scaler.fit(iris_df) iris_scaled=scaler.transform(iris_df) #transform()시 스케일 변환된 데이터 세트가 Numpy ndarray 이므로 반환돼 이를 DataFrame으로 변환 iris_df_scaled=pd.DataFrame(data=iris_scaled, columns=iris.feature_names) print(&#39;feature 들의 평균 값&#39;) print(iris_df_scaled.mean()) print(&#39; nfeature 들의 분산 값&#39;) print(iris_df_scaled.var()) #아래 결과와 같이 모든 칼럼 값의 평균이 0에 아주 가까운 값, 분산은 1에 가까운 값으로 변환됨을 알 수 있다. #망충한 질문인데,, -1.690315e-15&lt;-얘가 0이랑 가가운거야?? 최소 -15아님?? 둘다 (-)부호잖어..? . feature 들의 평균 값 sepal length (cm) -1.690315e-15 sepal width (cm) -1.842970e-15 petal length (cm) -1.698641e-15 petal width (cm) -1.409243e-15 dtype: float64 feature 들의 분산 값 sepal length (cm) 1.006711 sepal width (cm) 1.006711 petal length (cm) 1.006711 petal width (cm) 1.006711 dtype: float64 . MinMaxScaler . 데이터값을 0과 1사이의 범위 값으로 변환함.(음수 값이 있으면 -1에서 1로 변환함) . | 질문이 데이터 분포가 가우시안 분포가 아닌경우 MinMaxScaler을 적용할수 있다는데, 가우시안 이면 평균이 1이니까 이부분을 충족 못시켜서 가우시안 일때 쓰면 안된다는 건가? . | . from sklearn.preprocessing import MinMaxScaler #MinMaxScaler객체 생성 scaler=MinMaxScaler() #MinMaxScaler로 데이터 세트 변환, fit()과 transform() 호출 scaler.fit(iris_df) iris_scaled=scaler.transform(iris_df) #transform()시 스케일 변환된 데이터 세트가 Numpy ndarray이므로 반환돼 이를 DataFrame으로 변환 iris_df_scaled=pd.DataFrame(data=iris_scaled, columns=iris.feature_names) print(&#39;feature 들의 최솟값&#39;) print(iris_df_scaled.min()) print(&#39; nfeature 들의 최댓값&#39;) print(iris_df_scaled.max()) #모든 피처에서 0~1사이 값으로 변환되는 스케일링이 적용됬음을 알 수 있다. . feature 들의 최솟값 sepal length (cm) 0.0 sepal width (cm) 0.0 petal length (cm) 0.0 petal width (cm) 0.0 dtype: float64 feature 들의 최댓값 sepal length (cm) 1.0 sepal width (cm) 1.0 petal length (cm) 1.0 petal width (cm) 1.0 dtype: float64 . 6.&#53440;&#51060;&#53440;&#45769;&#51004;&#47196; &#49373;&#51316;&#51088; &#50696;&#52769;&#54616;&#44592; . !pip install matplotlib !pip install seaborn import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns %matplotlib inline titanic_df = pd.read_csv(&#39;./train.csv&#39;) titanic_df.head(3) #Seaborn은 Matplotlib을 기반으로 다양한 색상 테마와 통계용 차트 등의 기능을 추가한 시각화 패키지 #Matplotlib는 파이썬에서 데이터를 차트나 플롯(Plot)으로 그려주는 라이브러리 패키지 . Requirement already satisfied: matplotlib in c: users hyo anaconda3 envs py39 lib site-packages (3.5.1) Requirement already satisfied: numpy&gt;=1.17 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (1.21.5) Requirement already satisfied: pillow&gt;=6.2.0 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (9.0.1) Requirement already satisfied: cycler&gt;=0.10 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (0.11.0) Requirement already satisfied: python-dateutil&gt;=2.7 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (2.8.2) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (1.4.2) Requirement already satisfied: fonttools&gt;=4.22.0 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (4.31.2) Requirement already satisfied: packaging&gt;=20.0 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (21.3) Requirement already satisfied: pyparsing&gt;=2.2.1 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib) (3.0.7) Requirement already satisfied: six&gt;=1.5 in c: users hyo anaconda3 envs py39 lib site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib) (1.16.0) Requirement already satisfied: seaborn in c: users hyo anaconda3 envs py39 lib site-packages (0.11.2) Requirement already satisfied: matplotlib&gt;=2.2 in c: users hyo anaconda3 envs py39 lib site-packages (from seaborn) (3.5.1) Requirement already satisfied: scipy&gt;=1.0 in c: users hyo anaconda3 envs py39 lib site-packages (from seaborn) (1.7.3) Requirement already satisfied: pandas&gt;=0.23 in c: users hyo anaconda3 envs py39 lib site-packages (from seaborn) (1.4.1) Requirement already satisfied: numpy&gt;=1.15 in c: users hyo anaconda3 envs py39 lib site-packages (from seaborn) (1.21.5) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (1.4.2) Requirement already satisfied: pillow&gt;=6.2.0 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (9.0.1) Requirement already satisfied: python-dateutil&gt;=2.7 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (2.8.2) Requirement already satisfied: cycler&gt;=0.10 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (0.11.0) Requirement already satisfied: fonttools&gt;=4.22.0 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (4.31.2) Requirement already satisfied: packaging&gt;=20.0 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (21.3) Requirement already satisfied: pyparsing&gt;=2.2.1 in c: users hyo anaconda3 envs py39 lib site-packages (from matplotlib&gt;=2.2-&gt;seaborn) (3.0.7) Requirement already satisfied: pytz&gt;=2020.1 in c: users hyo anaconda3 envs py39 lib site-packages (from pandas&gt;=0.23-&gt;seaborn) (2021.3) Requirement already satisfied: six&gt;=1.5 in c: users hyo anaconda3 envs py39 lib site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib&gt;=2.2-&gt;seaborn) (1.16.0) . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | male | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | NaN | S | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | female | 38.0 | 1 | 0 | PC 17599 | 71.2833 | C85 | C | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | female | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | NaN | S | . print(&#39; n ### 학습 데이터 정보 ### n&#39;) print(titanic_df.info()) #DataFrame의 info()메서드를 통해 각 전체 행 수, 컬럼에 대한 정보, 결측치 있는지 없는지, 데이터 타입, 메모리 사용량 등을 확인함. #RangeIndex는 DataFrame 인덱스의 범위를 나타내 전체 행의 개수를 알수 있음. #칼럼 수는 12개, 2개의 칼럼이 float64 타입, 5개의 칼럼이 object타입임. . ### 학습 데이터 정보 ### &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 891 entries, 0 to 890 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 PassengerId 891 non-null int64 1 Survived 891 non-null int64 2 Pclass 891 non-null int64 3 Name 891 non-null object 4 Sex 891 non-null object 5 Age 891 non-null float64 6 SibSp 891 non-null int64 7 Parch 891 non-null int64 8 Ticket 891 non-null object 9 Fare 891 non-null float64 10 Cabin 891 non-null object 11 Embarked 891 non-null object dtypes: float64(2), int64(5), object(5) memory usage: 83.7+ KB None . titanic_df[&#39;Age&#39;].fillna(titanic_df[&#39;Age&#39;].mean(),inplace=True) titanic_df[&#39;Cabin&#39;].fillna(&#39;N&#39;, inplace=True) titanic_df[&#39;Embarked&#39;].fillna(&#39;N&#39;,inplace=True) print(&#39;데이터 세트 Null 값 개수&#39;, titanic_df.isnull().sum().sum()) . 데이터 세트 Null 값 개수 0 . print(&#39; Sex 값 분포: n&#39;, titanic_df[&#39;Sex&#39;].value_counts()) print(&#39; n Cabin 값 분포: n&#39;, titanic_df[&#39;Cabin&#39;].value_counts()) print(&#39; n Embarked 값 분포: n&#39;, titanic_df[&#39;Embarked&#39;].value_counts()) . Sex 값 분포: male 577 female 314 Name: Sex, dtype: int64 Cabin 값 분포: N 687 C23 C25 C27 4 G6 4 B96 B98 4 C22 C26 3 ... E34 1 C7 1 C54 1 E36 1 C148 1 Name: Cabin, Length: 148, dtype: int64 Embarked 값 분포: S 644 C 168 Q 77 N 2 Name: Embarked, dtype: int64 . titanic_df[&#39;Cabin&#39;]=titanic_df[&#39;Cabin&#39;].str[:1] print(titanic_df[&#39;Cabin&#39;].head(3)) . 0 N 1 C 2 N Name: Cabin, dtype: object . titanic_df.groupby([&#39;Sex&#39;, &#39;Survived&#39;])[&#39;Survived&#39;].count() #survived 0은 사망, 1은 생존이다. . Sex Survived female 0 81 1 233 male 0 468 1 109 Name: Survived, dtype: int64 . sns.barplot(x=&#39;Pclass&#39;, y=&#39;Survived&#39;, hue=&#39;Sex&#39;, data=titanic_df) . &lt;AxesSubplot:xlabel=&#39;Pclass&#39;, ylabel=&#39;Survived&#39;&gt; . #입력 age에 따라 구분 값을 반환하는 함수&#39;get_category&#39;를 def로 설정해줌. #age에 어떤 값을 넣어줄진 모르지만 &lt;=-1이면 Unknown값 나오게 하는 함수 &#39;get_category&#39; def를 통해 정의함. def get_category(age): cat=&#39;&#39; # 구분 카테고리를 담을 빈 str 생성 if age &lt;=-1: cat=&#39;Unknown&#39; elif age &lt;=5: cat=&#39;Baby&#39; elif age &lt;=12: cat=&#39;Child&#39; elif age &lt;=18: cat=&#39;Teenager&#39; elif age &lt;=25: cat=&#39;Student&#39; elif age &lt;=35: cat=&#39;Young Adult&#39; elif age &lt;=60: cat=&#39;Adult&#39; else : cat=&#39;Elderly&#39; return cat #막대그래프의 크기 figure를 더 크게 설정 plt.figure(figsize=(10,6)) #X축의 값을 순차적으로 표시하기 위한 설정 group_names=[&#39;Unkown&#39;,&#39;Baby&#39;,&#39;Child&#39;,&#39;Teenager&#39;,&#39;Student&#39;,&#39;Young Adult&#39;,&#39;Adult&#39;,&#39;Elderly&#39;] #lambda가 함수 get_category(x)를 적용해준다는 거임. #titanic_df의 칼럼 &#39;Age&#39; 값을 get_category(x)의 x에 넣어주고 이에 반환값을 titanic_df의 칼럼 &#39;Age_cat&#39;에 따른 피처값으로 넣어줌. titanic_df[&#39;Age_cat&#39;]=titanic_df[&#39;Age&#39;].apply(lambda x: get_category(x)) sns.barplot(x=&#39;Age_cat&#39;, y=&#39;Survived&#39;,hue=&#39;Sex&#39;, data=titanic_df, order=group_names) #그래프에서 나이별 분류, 즉 Age_cat의 칼럼을 그려주기 위해 추가 한거니까 그래프 그리고, 다시 해당 칼럼을 삭제해줌. titanic_df.drop(&#39;Age_cat&#39;, axis=1, inplace=True) #위의 과정은 그래프에 그리기 위해 데이터 프레임에 칼럼 추가하고/ 그래프 그리고/ 다시 삭제하는 과정임. . from sklearn.preprocessing import LabelEncoder from sklearn import preprocessing #함수 encode_features 를/ dataDF에 들어갈/ 임의의 데이터 프레임의 어떤 칼럼(features)을 레이블 인코딩하도록/ 설정함. def encode_features(dataDF): features=[&#39;Cabin&#39;, &#39;Sex&#39;, &#39;Embarked&#39;] for feature in features: le=preprocessing.LabelEncoder() le=le.fit(dataDF[feature]) dataDF[feature]=le.transform(dataDF[feature]) return dataDF titanic_df=encode_features(titanic_df) titanic_df.head() #&#39;Cabin&#39;, &#39;Sex&#39;, &#39;Embarked&#39; 속성이 숫자형으로 바뀐것을 알 수 있음. # 참고로 위위위위에서 titanic_df[&#39;Cabin&#39;]=titanic_df[&#39;Cabin&#39;].str[:1] 해서 선실 앞자리 별로 레이블 인코딩 됨. . PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked . 0 1 | 0 | 3 | Braund, Mr. Owen Harris | 1 | 22.0 | 1 | 0 | A/5 21171 | 7.2500 | 7 | 3 | . 1 2 | 1 | 1 | Cumings, Mrs. John Bradley (Florence Briggs Th... | 0 | 38.0 | 1 | 0 | PC 17599 | 71.2833 | 2 | 0 | . 2 3 | 1 | 3 | Heikkinen, Miss. Laina | 0 | 26.0 | 0 | 0 | STON/O2. 3101282 | 7.9250 | 7 | 3 | . 3 4 | 1 | 1 | Futrelle, Mrs. Jacques Heath (Lily May Peel) | 0 | 35.0 | 1 | 0 | 113803 | 53.1000 | 2 | 3 | . 4 5 | 0 | 3 | Allen, Mr. William Henry | 1 | 35.0 | 0 | 0 | 373450 | 8.0500 | 7 | 3 | . #(임의의 df를 설정하여 함수를 만든거임.) #Null 처리 함수 def fillna(df): df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean(), inplace=True) df[&#39;Cabin&#39;].fillna(&#39;N&#39;, inplace=True) df[&#39;Embarked&#39;].fillna(&#39;N&#39;, inplace=True) df[&#39;Fare&#39;].fillna(0, inplace=True) return df #머신러닝 알고리즘에 불필요한 속성 제거 def drop_features(df): df.drop([&#39;PassengerId&#39;, &#39;Name&#39;, &#39;Ticket&#39;], axis=1, inplace=True) return df #레이블 인코딩 수행 def format_features(df): df[&#39;Cabin&#39;]=df[&#39;Cabin&#39;].str[:1] features=[&#39;Cabin&#39;, &#39;Sex&#39;, &#39;Embarked&#39;] for feature in features: le=LabelEncoder() le=le.fit(df[feature]) df[feature]=le.transform(df[feature]) return df #앞에서 설정한 데이터 전처리 함수 호출( 위에 나온 3개를 모두 수행하는 함수) def transform_features(df): df=fillna(df) df=drop_features(df) df=format_features(df) return df ### 위 세 함수 모두 마지막에 return df를 입력해주었는데 ### 그렇게 함으로써 아래에서 df=df, df=df, df=df 를 통해 df를 함수를 이용한 결과로 업데이트 해줄 수 있다. . titanic_df=pd.read_csv(&#39;./train.csv&#39;) y_titanic_df=titanic_df[&#39;Survived&#39;] #생존값을 y에 넣어줌(들어가는 값은 0,1) X_titanic_df=titanic_df.drop(&#39;Survived&#39;, axis=1) #y에 넣줬으니까 X에는 빼줌) X_titanic_df=transform_features(X_titanic_df) #X에서 전처리 해줌 . from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=11) . from sklearn.tree import DecisionTreeClassifier from sklearn.ensemble import RandomForestClassifier from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score #결정트리, Random Forest, 로지스틱 회귀를 이한 사이킷런 Classifier 클래스 생성 dt_clf=DecisionTreeClassifier(random_state=11) rf_clf=RandomForestClassifier(random_state=11) lr_clf=LogisticRegression() #DecisionTreeClassifier 학습/예측/평가 dt_clf.fit(X_train, y_train) dt_pred=dt_clf.predict(X_test) print(&#39;DecisionTreeClassifier 정확도:{0:.4f}&#39;.format(accuracy_score(y_test, dt_pred))) # RandomForestClassifier 학습/예측/평가 rf_clf.fit(X_train, y_train) rf_pred=rf_clf.predict(X_test) print(&#39;RandomForestClassifier 정확도:{0:.4f}&#39;.format(accuracy_score(y_test, rf_pred))) # LogisticRegression 학습/예측/평가 ###이산적인 데이터인데 회귀로 예측할 수도 있음. 꼭 연속적인 것만 해야 하는건 아님 lr_clf.fit(X_train, y_train) lr_pred=lr_clf.predict(X_test) print(&#39;LogisticRegression 정확도:{0:.4f}&#39;.format(accuracy_score(y_test, lr_pred))) #LogisticRegression의 정확도가 가장 높게 나왔지만 아직 최적화 작업을 수행하지 않았고, #데이터 양도 충분하지 않기에 어떤 알고리즘이 가장 좋다고 말할순 없음. . DecisionTreeClassifier 정확도:0.7877 RandomForestClassifier 정확도:0.8547 LogisticRegression 정확도:0.8492 . C: Users hyo anaconda3 envs py39 lib site-packages sklearn linear_model _logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1): STOP: TOTAL NO. of ITERATIONS REACHED LIMIT. Increase the number of iterations (max_iter) or scale the data as shown in: https://scikit-learn.org/stable/modules/preprocessing.html Please also refer to the documentation for alternative solver options: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression n_iter_i = _check_optimize_result( . from sklearn.model_selection import KFold def exec_kfold(clf, folds=5): #폴드 세트를 5개인 KFold객체를 생성, 폴드 수만큼 예측결과 저장을 위한 리스트 객체 생성. kfold=KFold(n_splits=folds) scores=[] #KFold 교차 검증 수행. #enumerate란 리스트나 튜플같이 하나씩 불러올때 해당 원소가 몇번째인지 알려주는 거임. for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)): #X_train_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성 X_train, X_test=X_titanic_df.values[train_index], X_titanic_df.values[test_index] y_train, y_test=y_titanic_df.values[train_index], y_titanic_df.values[test_index] #Classifier 학습, 예측, 정확도 계산 clf.fit(X_train, y_train) predictions=clf.predict(X_test) accuracy=accuracy_score(y_test, predictions) scores.append(accuracy) print(&quot;교차 검증 {0} 정확도: {1:.4f}&quot;.format(iter_count, accuracy)) #5개 fold에서의 평균 정확도 계산 mean_score=np.mean(scores) print(&quot;평균 정확도: {0:.4f}&quot;.format(mean_score)) #exec_kfold 호출 exec_kfold(dt_clf, folds=5) #질문이 왜 학습 k폴드로 나눠줄때 y_titanic_df은 빼고 해주는 거임??? #-어 왜냐면 그건 straified kfold에서만 해주는 거라서. kfold에선 안해줘도 됨. #질문이 iter_count=0안해도 1,2,3,4,5나오는 이유 #-그건 enumerate해줬기 때문, 기본이 0부터 시작이고 star=값 설정해주면 그에 따라 시작이 달라질수 있음. . 교차 검증 0 정확도: 0.7542 교차 검증 1 정확도: 0.7809 교차 검증 2 정확도: 0.7865 교차 검증 3 정확도: 0.7697 교차 검증 4 정확도: 0.8202 평균 정확도: 0.7823 . X_titanic_df . Pclass Sex Age SibSp Parch Fare Cabin Embarked . 0 3 | 1 | 22.000000 | 1 | 0 | 7.2500 | 7 | 3 | . 1 1 | 0 | 38.000000 | 1 | 0 | 71.2833 | 2 | 0 | . 2 3 | 0 | 26.000000 | 0 | 0 | 7.9250 | 7 | 3 | . 3 1 | 0 | 35.000000 | 1 | 0 | 53.1000 | 2 | 3 | . 4 3 | 1 | 35.000000 | 0 | 0 | 8.0500 | 7 | 3 | . ... ... | ... | ... | ... | ... | ... | ... | ... | . 886 2 | 1 | 27.000000 | 0 | 0 | 13.0000 | 7 | 3 | . 887 1 | 0 | 19.000000 | 0 | 0 | 30.0000 | 1 | 3 | . 888 3 | 0 | 29.699118 | 1 | 2 | 23.4500 | 7 | 3 | . 889 1 | 1 | 26.000000 | 0 | 0 | 30.0000 | 2 | 0 | . 890 3 | 1 | 32.000000 | 0 | 0 | 7.7500 | 7 | 2 | . 891 rows × 8 columns . y_titanic_df . 0 0 1 1 2 1 3 1 4 0 .. 886 0 887 1 888 0 889 1 890 0 Name: Survived, Length: 891, dtype: int64 . train_index #train_index가 정의되지 않는 이유는 def로 함수를 설정했고, 그 안에 있기 때문. # 함수 안에서 정의한거면 쓸수 없음- 이런걸 지역변수라고 함. #함수밖에 for문으로 돌린거면 train_index의 값이 나옴- 이런걸 전역변수라 함. . NameError Traceback (most recent call last) Input In [93], in &lt;cell line: 1&gt;() -&gt; 1 train_index NameError: name &#39;train_index&#39; is not defined . 지역변수와 전역변수 | . a=4 . def function(): a=2 print(a) . function() . 2 . a #맨 위에서 a=4를 안써줬으면 에러나왔을거임. 함수안에서 정의된 a는 지역변수라 나올수 없어서. . 4 . from sklearn.model_selection import cross_val_score scores=cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5) for iter_count, accuracy in enumerate(scores): print(&quot;교차 검증 {0} 정확도: {1:.4f}&quot;.format(iter_count, accuracy)) print(&quot;평균 정확도: {0:.4f}&quot;.format(np.mean(scores))) . 교차 검증 0 정확도: 0.7430 교차 검증 1 정확도: 0.7753 교차 검증 2 정확도: 0.7921 교차 검증 3 정확도: 0.7865 교차 검증 4 정확도: 0.8427 평균 정확도: 0.7879 . from sklearn.model_selection import GridSearchCV parameters={&#39;max_depth&#39;:[2,3,5,10], &#39;min_samples_split&#39;:[2,3,5], &#39;min_samples_leaf&#39;:[1,5,8]} grid_dclf=GridSearchCV(dt_clf, param_grid=parameters, scoring=&#39;accuracy&#39;, cv=5) grid_dclf.fit(X_train, y_train) print(&#39;GridSearchCV 최적 하이퍼 파라미터:&#39;, grid_dclf.best_params_) print(&#39;GridSearchCV 최고 정확도: {0:.4f}&#39;.format(grid_dclf.best_score_)) best_dclf=grid_dclf.best_estimator_ #GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. dpredictions=best_dclf.predict(X_test) accuracy=accuracy_score(y_test, dpredictions) print(&#39;테스트 세트에서의 DecisionTreeClassifier 정확도: {0:.4f}&#39;.format(accuracy)) #하이퍼 파라미터 변경 전보다 약 0.08이상 증가 #테스트용 데이터 세트가 작기 때문에 수치상으로 예측 성능이 많이 증가한 것 처럼 보임. . GridSearchCV 최적 하이퍼 파라미터: {&#39;max_depth&#39;: 3, &#39;min_samples_leaf&#39;: 5, &#39;min_samples_split&#39;: 2} GridSearchCV 최고 정확도: 0.7992 테스트 세트에서의 DecisionTreeClassifier 정확도: 0.8715 . &#54217;&#44032; . 머신러닝은 데이터 가공/변환, 모델 학습/예측, 긜고 평가의 과정으로 구성됩니다. 성능 평가 지표는 일반적으로 모델이 분류냐 회귀냐에 따라 여러 종류로 나뉩니다. 회귀의 경우 대부분 실제 값과 예측값의 오차 평균값에 기반합니다(기본적으로 예측 오차를 가지고 정규화 수준을 재가공 하는 방법). | 분류의 평가 방법은 정확도만 가지고 판단했다가는 잘못된 평가 결과에 빠질 수 있음. 특히 이진 분류에서는 정확도보다는 다른 성능 평가 지표가 더 중시됨. 분류의 성능 평가 지표: 정확도, 오차행렬, 정밀도, 재한율, F1 스코오, ROC AUC | 분류는 결정 클래스 값 종류 유형에 따라 2개의 결과값만 가지는 이진 분류와 여러개의 결정 클래스 값을 가지는 멀티 분류로 나뉨. 특히 이진 분류에서 성능 평가 지표가 중요함. | . | . | . &#51221;&#54869;&#46020; . 정확도: 예측 결과가 동일한 데이터 건수/전체 예측 데이터 건수 | 정확도는 직관적으로 모델 예측 성능을 나타내는 지표이지만 이진 분류의 경우 데이터의 구성에 따라 ml모델의 성능을 왜곡할 수 있음. 그래서 정확도 말고 다른 성능 지표들이 필요함. | . &#51060;&#51652;&#48516;&#47448;&#50640;&#49436; &#51221;&#54869;&#46020; &#51648;&#54364;&#44032; &#50612;&#46523;&#44172; ml&#47784;&#45944;&#51032; &#49457;&#45733;&#51012; &#50780;&#44257;&#54624;&#44620; . 타이타닉의 예측 결과에서 여자의 생존률이 남자보다 높게 나오는데 전체 요소를 배제하고 성별만으로 예측해도 이와 비슷한 성능 결과가 나옴-&gt;단순 이진분류인 성별로 예측도의 정확성을 높임 | . DummyClassifier란 피처값을 무시하고 더 간단하게 비교 할수 있게 해주는 거임. The specific behavior of the baseline is selected with the strategy parameter. | . #얘로 지금 예측하겠다는게 아니라 이런 일을 수행하는 함수를 만들어 준것일 뿐 from sklearn.base import BaseEstimator class MyDummyClassifier(BaseEstimator): # fit()메서드는 아무것도 학습하지 않음. def fit(self, X, y=None): pass #predict()메서드는 단순히 피처가 1이면 0, 아니면 1로 예측 def predict (self, X): pred=np.zeros( (X.shape[0], 1)) #zeros 함수는 0으로 채워진 배열을 만듦( X의 행수 만큼 행, 열은 1개), #pred를 업더이트 시켜주기 위해 임의로 값 채워놓은것 뿐 for i in range (X.shape[0]): if X[&#39;Sex&#39;].iloc[i]==1: pred[i]=0 else: pred[i]=1 return pred . from sklearn.preprocessing import LabelEncoder from sklearn import preprocessing def fillna(df): df[&#39;Age&#39;].fillna(df[&#39;Age&#39;].mean(), inplace=True) df[&#39;Cabin&#39;].fillna(&#39;N&#39;, inplace=True) df[&#39;Embarked&#39;].fillna(&#39;N&#39;, inplace=True) df[&#39;Fare&#39;].fillna(0, inplace=True) return df #머신러닝 알고리즘에 불필요한 속성 제거 def drop_features(df): df.drop([&#39;PassengerId&#39;, &#39;Name&#39;, &#39;Ticket&#39;], axis=1, inplace=True) return df #레이블 인코딩 수행 def format_features(df): df[&#39;Cabin&#39;]=df[&#39;Cabin&#39;].str[:1] features=[&#39;Cabin&#39;, &#39;Sex&#39;, &#39;Embarked&#39;] for feature in features: le=LabelEncoder() le=le.fit(df[feature]) df[feature]=le.transform(df[feature]) return df #앞에서 설정한 데이터 전처리 함수 호출( 위에 나온 3개를 모두 수행하는 함수) def transform_features(df): df=fillna(df) df=drop_features(df) df=format_features(df) return df . import pandas as pd import numpy as np from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score titanic_df=pd.read_csv(&#39;./train.csv&#39;) #원본 데이터를 재로딩 y_titanic_df=titanic_df[&#39;Survived&#39;] #데이터 가공 X_titanic_df=titanic_df.drop(&#39;Survived&#39;, axis=1) X_titanic_df=transform_features(X_titanic_df) #데이터 전처리 X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, test_size=0.2, random_state=0) #학습 데이터/테스트 데이터 분할 #위에서 생성한 Dummy Classifier를 이용해 학습/에측/평가 수행 myclf=MyDummyClassifier() myclf.fit(X_train, y_train) mypredictions=myclf.predict(X_test) print(&#39;Dummy Classifier의 정확도: {0:.4f}&#39;.format(accuracy_score(y_test, mypredictions))) . Dummy Classifier의 정확도: 0.7877 . #MNIST 데이터 세트를 변환해 불균형한 데이터 세트로 만든 후 정확도 지표 적용시 어떤 문제점이 있는지 알아보자 | . from sklearn.datasets import load_digits from sklearn.model_selection import train_test_split from sklearn.base import BaseEstimator from sklearn.metrics import accuracy_score import numpy as np import pandas as pd #Dummy Classifier를 생성하기 class MyFakeClassifier(BaseEstimator): def fit(self, X, y): #얘는 그냥 X,y를 받을수 있다는 의미..? 밑에 pass쓴거는 함수만 쓰면 컴파일 돌렷을 때 오류날수 있어서 쓴거. pass #입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0값으로 만들어서 반환, 위의 X와 같은거 넣으란거 아님 def predict(self, X): return np.zeros( (len(X), 1), dtype=bool) # bool은 (True or False)을 바이트 형식으로 저장해 놓은것 #불균형한 데이터와 세트 만들기 #사이킷런의 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩, digits이 모든 문자열을 숫자열로 바꿔주는 것으 의미함. digits=load_digits() #digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, 7번이 아니면 false이고 0으로 변환 y=(digits.target==7).astype(int) X_train, X_test, y_train, y_test=train_test_split(digits.data, y, random_state=11) . digits.data . array([[ 0., 0., 5., ..., 0., 0., 0.], [ 0., 0., 0., ..., 10., 0., 0.], [ 0., 0., 0., ..., 16., 9., 0.], ..., [ 0., 0., 1., ..., 6., 0., 0.], [ 0., 0., 2., ..., 12., 0., 0.], [ 0., 0., 10., ..., 12., 1., 0.]]) . digits.target . array([0, 1, 2, ..., 8, 9, 8]) . X_test . array([[ 0., 0., 7., ..., 3., 0., 0.], [ 0., 0., 0., ..., 0., 0., 0.], [ 0., 0., 6., ..., 0., 0., 0.], ..., [ 0., 1., 13., ..., 15., 3., 0.], [ 0., 0., 0., ..., 1., 0., 0.], [ 0., 0., 0., ..., 12., 0., 0.]]) . y_test . array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]) . #불균형한 레이블 분포도 확인 print(&#39;레이블 테스트 세트 크기:&#39;, y_test.shape) #[].shape이 (몇행,몇열) 인지 나옴 print(&#39;테스트 세트 레이블 0과 1의 분포도&#39;) print(pd.Series(y_test).value_counts()) #Dummy Classifier로 학습/예측/정확도 평가 fakeclf=MyFakeClassifier() fakeclf.fit(X_train, y_train) # &lt;-얜 걍 형식상 해주는건데 딱히 의미 없음 fakepred=fakeclf.predict(X_test) print(&#39;모든 예측을 0으로 하여도 정확도는: {:.3f}&#39;.format(accuracy_score(y_test, fakepred))) #모든 것을 0으로 예측하는 MyFakeClassifier의 정확도가 너무 높게 나옴. #그래서 밑에서 True/False, Positivw/Negative로 4분면으로 구성되는 오차행렬에 대해 배워보자. . 레이블 테스트 세트 크기: (450,) 테스트 세트 레이블 0과 1의 분포도 0 405 1 45 dtype: int64 모든 예측을 0으로 하여도 정확도는: 0.900 . . y_train . array([0, 0, 1, ..., 0, 0, 0]) . X_train . array([[ 0., 0., 3., ..., 12., 14., 7.], [ 0., 1., 9., ..., 10., 1., 0.], [ 0., 0., 0., ..., 0., 0., 0.], ..., [ 0., 0., 1., ..., 16., 13., 1.], [ 0., 1., 11., ..., 13., 16., 5.], [ 0., 0., 6., ..., 6., 0., 0.]]) . X_test . array([[ 0., 0., 7., ..., 3., 0., 0.], [ 0., 0., 0., ..., 0., 0., 0.], [ 0., 0., 6., ..., 0., 0., 0.], ..., [ 0., 1., 13., ..., 15., 3., 0.], [ 0., 0., 0., ..., 1., 0., 0.], [ 0., 0., 0., ..., 12., 0., 0.]]) . 인스턴스란 특정한 값 없이 이런 기능을 한다는 코드를 이런 기능 쓰기 위해 매개변수 넣어 주는 것을 말함. 클래스를 객체화한거라고 보면됨. 클래스란 비슷한 기능을 하는 함수를 모아놓은 느낌..?임. 예를 들어 클래스가 계산기라고 하면 그 안의 덧셈, 뺄셈 등의 기능을 모아놓은거임. | self 란게 객체의 인스턴스 그 자체를 말한다. 즉, 객체 자기 자신을 참조하는 매개변수인 셈임 | . 03 &#54217;&#44032; . &#50724;&#52264;&#54665;&#47148; . [[TN //// FP FN ////TP]] . | 이진 분류에서 성능 지표로 잘 활용됨 | 이진 분류의 예측 오류가 얼마인지와 더불어// 어떠한 유형의 예측 오류가 발생하고 있는지를 함께 나타내주는 지표. | 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매칭되는 지를 나타냄. 앞 문자 True/False는 예측값과 실제값이 &#39;같은가/다른가&#39;를 의미하고 뒤문자 Positive/Negative 는 예측 결과 값이 부정(0)/긍정(1)을 의미함. | ex) TN은 True Negative라는 의미이며 앞 True는 예측 클래스값과 실제 클래스 값이 같다는 의미이고, 뒤의 Negative는 예측값이 Negative라는 의미이다. 즉 예측을 Negative(0)으로 예측했는데, 실제 값도 Negative(0)이라는 의미이다. | TN, FP, FN, TP로 나오는 값을 조합하여 정확도, 정밀도, 재현율 값을 알 수 있음. | . | . #MyFakeClassifier의 예측결과인 fakepred와 실제 결과인 y_test를 #confusion_matrix()의 인자로 입력헤 오차행렬을 confusion_matrix()를 이용해 배열 형태로 출력 from sklearn.metrics import confusion_matrix confusion_matrix(y_test, fakepred) ###질문이 아니 y_test는 왜 안에 같이 써주는 거임? . array([[405, 0], [ 45, 0]], dtype=int64) . #TN 자리인 405의 의미는 0이라 에측했는데 0나온게 405개 #FP 자리인 0의 의미는 0이라 예측했는데 1나온게 0개 &gt; 그럴수 밖에 없는게 fakepred에서 0만 나오게 했으니까 1이 나올수 없음 #FN 자리인 45의 의미는 1이라 예측했는데 0나온게 45개 #TP 자리인 0의 의미는 1이라고 예측했는데 1나온게 0개&gt; 얘도 이럴수 밖에 없는게 0만 나오게 설정해서 그럼 위위 말처럼 . #FP: array[0,1] - 음성(0)이라 예측했는데, 양성(1)이 나옴 #FN: array[1,0] - 양성(1)이라 예측했는데, 음성(0)이 나옴 #TP: array[1,1] - 양성(0)이라 예측했는데, 양성(0)이 나옴 . &#51221;&#54869;&#46020; . 정확도는 예측값과 실제 값이 얼마나 동일한가에 대한 비율만으로 결정된다. 즉 오차행렬에서 True에 해당하는 값인 TN과 TP에 좌우된다. 정확도는 오차 행렬상에서 다음과 같이 정의될 수 있다. | 정확도=예측 결과와 실제 값이 동일한 건수/ 전체 데이터 수 =(TN+TP)/(TN+FP+FN+TP) | 일반적으로 불균형한 레이블 클래스를 가지는 이진 분류 모델에서는 많은 데이터 중에서 찾고자 하는 매우 적은 수의 결괏값에 Positive를 설정해 1값을 부여하고, 그렇지 않은 경우는 Negative로 0값을 부여하는 경우가 많다.(암:1, 건강:0) | . 불균형한 데이터 세트에서 정확도만으로는 성능이 떨어지는 이유: 불균형한 이진 분류 데이터 세트에서 Positive 데이터 건수가 매우 작기에 데이터에 기반한 ML알고리즘은 Positve 보다 Negative로 예측할 경향이 더 강해져 TN은 커지고 TP는 작아지게 된다. 또한 Negative로 예측할 때 정확도가 높아지기 때문에 FN이 매우 작고, Positive로 예측하는 경우가 작기에 FP역시 작아지게 된다. | 결과적으로 정확도 지표는 비대칭한 데이터 세트에서 Positive에 대한 예측 정확도를 판단하지 못한 채 Negative에 대한 예측 정확도만으로 분류의 정확도가 매우 높게 나타나는 수치적 판단 오류를 일으킴. | . | . &#51221;&#48128;&#46020;&#50752; &#51116;&#54788;&#50984; . 정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초첨을 맞춘 평가 지표이다. 앞서 만든 MyClassifier는 Positive(1)으로 예측한 TP값이 없기에 정밀도와 재현율 값이 모두 0이다. | . 정밀도= TP/(FP+TP) :: Positive로 예측한 대상 중에 예측값과 실제 값이 Positive로 일치한 데이터 건수 (비율) Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 양성 예측이라고도 함 | . | . 재현율= TP/(FN+TP) :: 실제 값이 Positive인 대상 중 예측값과 실제 값이 Positive로 일치한 데이터 건수 (비율) 민감도 또는 TPR이라고도 함. | . | . 재현율과 정밀도는 이진분류를 하는 상황에 따라 둘중 무엇이 더 중요하다고 간주될 수 있음. 보통 적게 나오는 것을 양성(1)으로 설정하여 요주인물로 보고 흔히 나오는 것을 음성(0)이라 다룸. 양성을 음성이라 했을때 큰일 나는 상황에는 재현율, 음성을 양성이라 했을때 큰일나는 상황엔 정밀도가 더 중요하다. | 재현율과 정밀도는 모두 TP을 높이는 초점을 두 지만, 재현율은 FN을 낮추는데, 정밀도는 FP를 낮추는데 초점을 둔다.&lt;-서로 보완적인 지표로 분류의 성능을 평가하는데 적용됨. | . #사이킷런은 정밀도 계산을 위해 precision_score()를, 재현율 계산을 위해 recall_score()를 API로 제공한다 #오차행렬 구하는 confusion_matrix, 정확도 위한 accuracy, 정밀도 위한 precision, 재현율 위한 recall을 한번에 호출하는 함수 get_clf_eval() from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix def get_clf_eval(y_test, pred): confusion=confusion_matrix(y_test, pred) accuracy=accuracy_score(y_test, pred) precision=precision_score(y_test, pred) recall=recall_score(y_test, pred) print(&#39;오차행렬&#39;) print(confusion) print(&#39;정확도:{0:.4f}, 정밀도:{1:.4f}, 재현율:{2:.4f}&#39;.format(accuracy, precision, recall)) . import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression ###질문이 회귀는 연속적인 값을 예측하는건데 왜나옴? 분류 의사결정 트리가 나와야 하지 않음? #원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할 titanic_df=pd.read_csv(&#39;./train.csv&#39;) y_titanic_df=titanic_df[&#39;Survived&#39;] X_titanic_df=titanic_df.drop(&#39;Survived&#39;, axis=1) X_titanic_df=transform_features(X_titanic_df) X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df, test_size=0.20, random_state=11) lr_clf=LogisticRegression() lr_clf = LogisticRegression(solver=&#39;liblinear&#39;) #최적화에 사용할 알고리즘이 solver이고 &#39;liblinear&#39;가 그 종류 lr_clf.fit(X_train, y_train) pred=lr_clf.predict(X_test) get_clf_eval(y_test, pred) . 오차 행렬 [[108 10] [ 14 47]] 정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705 . &#51221;&#48128;&#46020;/&#51116;&#54788;&#50984; &#53944;&#47112;&#51060;&#46300; &#50724;&#54532; . 정밀도 또는 재현율이 특별히 강조돼야 할 경우 분류의 결정 임곗값을 조정해 정밀도 또는 재현율의 수치를 높일 수 있다. 둘은 상호 보완적인 평가 지표이기에 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉬움. 이를 정밀도/재현율의 트레이드오프라고 함. | 이진 분류 모델에서 특정 데이터가 0이 될 확률이 10%, 1이 될 확률이 90%로 예측됐다면 최종예측은 더 큰 확률을 가진 1로 예측함. 일반적으로 이진 분류엣는 이 임계값을 0.5, 50%로 정하고 이 기준 값보다 확률이 크녀 P아니면 N으로 결정함. | 임계값 확률 결정의 기준이 됨 | 분류 결정 임계값은 Psitive 예측값을 결정하는 확률의 기준이 됨 | . | . #사이킷런을 개별 데이터별로 예측 확률을 반환하는 메서드인 predict_proba()를 제공함. #학습이 완료된 사이킷런 Classifier 객체에서 호출이 가능하며 테스트 피처 세트를 파라미터로 입력해주면 #테스트 피처 레코드의 개별 클래스 예측 확률을 반환해줌. #차이점은 반환결과가 predict()-&gt;예측 결과 클래스 값, predict_proba()-&gt;예측 확률 결과 #반환되는 ndarray는 첫 번째 칼럼이 클래스 값 0에 대한 예측확률, 두 번째 칼럼이 클래스 값 1에 대한 에측 확률임. . pred_proba=lr_clf.predict_proba(X_test) print(&#39;pred_proba() 결과 Shape : {0}&#39;.format(pred_proba.shape)) print(&#39;pred_proba array에서 앞 3개만 샘플로 추출 n:&#39;,pred_proba[:3]) #예측 확률 array와 예측 결괏값 array를 병합(concatenate)해 예측 확률과 결괏값을 한눈에 확인 pred=lr_clf.predict(X_test) pred_proba_result=np.concatenate([pred_proba, pred.reshape(-1,1)], axis=1) #shape에서 음수도 같이 있을때는, 양수는 먼저 열 배열후 #음수는 가변적으로 알어서 행 배열의미. print(&#39;두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 n&#39;, pred_proba_result[:3]) ###어디서 부터 잘못됬니,,, . pred_proba() 결과 Shape : (179, 2) pred_proba array에서 앞 3개만 샘플로 추출 : [[0.44935225 0.55064775] [0.86335511 0.13664489] [0.86429643 0.13570357]] 두 개의 class 중에서 더 큰 확률을 클래스 값으로 예측 [[0.44935225 0.55064775 1. ] [0.86335511 0.13664489 0. ] [0.86429643 0.13570357 0. ]] . #정해진 임계값을 만족하는 ndarry칼럼위치를 최종예측하는 클래스--&gt;Binarizer from sklearn.preprocessing import Binarizer X=[[1, -1, 2], [2, 0, 0], [0, 1.1, 1.2]] # X의 개별 원소들이 분류결정 임계값인 threshold(1.1)값보다 같거나 작으면 0을, 크면 1을 반환. binarizer=Binarizer(threshold=1.1) print(binarizer.fit_transform(X)) . [[0. 0. 1.] [1. 0. 0.] [0. 0. 1.]] . from sklearn.preprocessing import Binarizer #Binarizer의 threshold 설정값 0.5가 분류 결정 임계값임. custom_threshold=0.5 #predict_proba() 반환값의 두 번째 칼럼, 즉 Positive(1) 클래스 칼럼만 추출해 Binarizer를 적용 pred_proba_1=pred_proba[:,1].reshape(-1,1) binarizer=Binarizer(threshold=custom_threshold).fit(pred_proba_1) custom_predict=binarizer.transform(pred_proba_1) get_clf_eval(y_test, custom_predict) ###값 다름,,ㅠㅠ . 오차 행렬 [[108 10] [ 14 47]] 정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705 . custom_threshold=0.4 pred_proba_1=pred_proba[:,1].reshape(-1,1) binarizer=Binarizer(threshold=custom_threshold).fit(pred_proba_1) #임계값 0.4로 값이 1인 칼럼만 넣어서 예측해본거 custom_predict=binarizer.transform(pred_proba_1) get_clf_eval(y_test, custom_predict) ####&lt;-ㅜㅠㅠ . 오차 행렬 [[97 21] [11 50]] 정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197 . 임계값을 낮추니까 재현율이 올라가고 정밀도가 떨어짐. 그 이유는 분류 결정 임계값은 Psitive 예측값을 결정하는 확률의 기준이 됨. 확률이 0.5가 아닌 0.4부터 Positve로 예측을 더 너그럽게 하기 때문. -&gt;임계값 낮출수록 P로 예측을 더 많이 하기에 True 값이 많아짐. Positive 예측값이 많아지면 상대적으로 재현율이 높아짐. 양성 예측을 많이 하다 보니 실제 양성을 음성으로 예측할 횟수가 줄어들기 때문. 즉, (분자-TP가 커지고 분모-TP커지고, 분모-FN가 작아짐) | . | . #임계값을 0.4로 부터 0.6까지 0.05씩 증가시키며 평가 지표를 작설할건데 이를 위해 get_eval_by_threshold()를 써줌 #테스트를 수행할 모든 임계값을 리스트 객체로 저장 thresholds=[0.4, 0.45, 0.50, 0.55, 0.60] def get_eval_by_threshold(y_test, pred_proba_c1, thresholds): #thresholds list객체 내의 값을 차례로 iteration하면서 Evaluation 수행. for custom_threshold in thresholds: binarizer=Binarizer(threshold=custom_threshold).fit(pred_proba_c1) custom_predict=binarizer.transform(pred_proba_c1) print(&#39;임계값:&#39;,custom_threshold) get_clf_eval(y_test, custom_predict) get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1,1), thresholds) . 임계값: 0.4 오차 행렬 [[97 21] [11 50]] 정확도: 0.8212, 정밀도: 0.7042, 재현율: 0.8197 임계값: 0.45 오차 행렬 [[105 13] [ 13 48]] 정확도: 0.8547, 정밀도: 0.7869, 재현율: 0.7869 임계값: 0.5 오차 행렬 [[108 10] [ 14 47]] 정확도: 0.8659, 정밀도: 0.8246, 재현율: 0.7705 임계값: 0.55 오차 행렬 [[111 7] [ 16 45]] 정확도: 0.8715, 정밀도: 0.8654, 재현율: 0.7377 임계값: 0.6 오차 행렬 [[113 5] [ 17 44]] 정확도: 0.8771, 정밀도: 0.8980, 재현율: 0.7213 . from sklearn.metrics import precision_recall_curve #레이블 값이 1일 때의 예측 확률을 추출 pred_proba_class1=lr_clf.predict_proba(X_test)[:, 1] #열 두번째거 (이름:1) 빼온거 #실제값 데이터 세트와 레이블 값이 1일때 예측 확률을 precision_recall_curve 인자로 입력 precisions, recalls, thresholds=precision_recall_curve(y_test, pred_proba_class1) ####&gt;??? print(&#39;반환된 분류 결정 임계값 배열의 Shape:&#39;, thresholds.shape) #반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임계값을 15 step으로 추출 thr_index=np.arange(0, thresholds.shape[0], 15) # 첫항이 0, 끝항이 thresholds.shape[0]=147, 간격이 15 print(&#39;샘플 추출을 위한 임계값 배열의 index 10개:&#39;,thr_index) print(&#39;샘플용 10개의 임계값: &#39;,np.round(thresholds[thr_index], 2)) #15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 print(&#39;샘플 임계값별 정밀도: &#39;, np.round(precisions[thr_index], 3)) print(&#39;샘플 임계값별 재현율: &#39;, np.round(recalls[thr_index], 3)) . 반환된 분류 결정 임계값 배열의 Shape: (147,) 샘플 추출을 위한 임계값 배열의 index 10개: [ 0 15 30 45 60 75 90 105 120 135] 샘플용 10개의 임계값: [0.12 0.13 0.15 0.17 0.26 0.38 0.49 0.63 0.76 0.9 ] 샘플 임계값별 정밀도: [0.379 0.424 0.455 0.519 0.618 0.676 0.797 0.93 0.964 1. ] 샘플 임계값별 재현율: [1. 0.967 0.902 0.902 0.902 0.82 0.77 0.656 0.443 0.213] . precision_recall_curve(y_test, pred_proba_class1) . (array([0.37888199, 0.375 , 0.37735849, 0.37974684, 0.38216561, 0.37820513, 0.38064516, 0.38311688, 0.38562092, 0.38815789, 0.39072848, 0.39597315, 0.40136054, 0.41843972, 0.42142857, 0.42446043, 0.43065693, 0.43382353, 0.43703704, 0.44029851, 0.44360902, 0.4469697 , 0.44615385, 0.4496124 , 0.4453125 , 0.44094488, 0.44444444, 0.44 , 0.44354839, 0.44715447, 0.45454545, 0.45833333, 0.46218487, 0.46610169, 0.47008547, 0.47413793, 0.47826087, 0.48245614, 0.48672566, 0.49107143, 0.4954955 , 0.5 , 0.50458716, 0.50925926, 0.51401869, 0.51886792, 0.52380952, 0.52884615, 0.53398058, 0.53921569, 0.54455446, 0.55 , 0.55555556, 0.56122449, 0.56701031, 0.57291667, 0.59139785, 0.59782609, 0.6043956 , 0.61111111, 0.61797753, 0.625 , 0.63218391, 0.63953488, 0.64705882, 0.64285714, 0.65060241, 0.65853659, 0.66666667, 0.675 , 0.6835443 , 0.69230769, 0.68831169, 0.68421053, 0.68 , 0.67567568, 0.68493151, 0.69444444, 0.70422535, 0.71428571, 0.71014493, 0.72058824, 0.73134328, 0.74242424, 0.75384615, 0.765625 , 0.76190476, 0.77419355, 0.78688525, 0.8 , 0.79661017, 0.81034483, 0.8245614 , 0.83928571, 0.83636364, 0.83333333, 0.8490566 , 0.86538462, 0.8627451 , 0.88 , 0.89795918, 0.89583333, 0.91489362, 0.93478261, 0.93181818, 0.93023256, 0.92857143, 0.95121951, 0.95 , 0.94871795, 0.94736842, 0.94594595, 0.94444444, 0.94285714, 0.94117647, 0.93939394, 0.9375 , 0.96774194, 0.96666667, 0.96551724, 0.96428571, 0.96296296, 0.96153846, 0.96 , 0.95833333, 0.95652174, 0.95454545, 0.95238095, 0.95 , 0.94736842, 0.94444444, 0.94117647, 0.9375 , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. , 1. ]), array([1. , 0.98360656, 0.98360656, 0.98360656, 0.98360656, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.96721311, 0.95081967, 0.95081967, 0.93442623, 0.91803279, 0.91803279, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.90163934, 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.8852459 , 0.86885246, 0.85245902, 0.83606557, 0.81967213, 0.81967213, 0.81967213, 0.81967213, 0.81967213, 0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.7704918 , 0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.70491803, 0.70491803, 0.70491803, 0.67213115, 0.6557377 , 0.63934426, 0.63934426, 0.62295082, 0.60655738, 0.59016393, 0.57377049, 0.55737705, 0.54098361, 0.52459016, 0.50819672, 0.49180328, 0.49180328, 0.47540984, 0.45901639, 0.44262295, 0.42622951, 0.40983607, 0.39344262, 0.37704918, 0.36065574, 0.3442623 , 0.32786885, 0.31147541, 0.29508197, 0.27868852, 0.26229508, 0.24590164, 0.24590164, 0.2295082 , 0.21311475, 0.19672131, 0.18032787, 0.16393443, 0.14754098, 0.13114754, 0.1147541 , 0.09836066, 0.08196721, 0.06557377, 0.03278689, 0.01639344, 0. ]), array([0.11573102, 0.11636723, 0.11819213, 0.12102774, 0.1234948 , 0.12350958, 0.12367553, 0.12730438, 0.12780981, 0.12838061, 0.12904511, 0.12928357, 0.12934056, 0.12941903, 0.13094562, 0.13174372, 0.13196918, 0.13221181, 0.13227898, 0.13536702, 0.13570357, 0.13571 , 0.1357405 , 0.13664489, 0.1375847 , 0.13821237, 0.13866563, 0.14423595, 0.14523152, 0.14927303, 0.14927478, 0.14996978, 0.15025071, 0.15029262, 0.15031481, 0.15252582, 0.15276924, 0.15344754, 0.15652281, 0.15768776, 0.15805796, 0.15920997, 0.15981388, 0.16929076, 0.17053651, 0.17288744, 0.17656591, 0.1828031 , 0.20840196, 0.21127162, 0.21146794, 0.21264241, 0.21814872, 0.22356775, 0.22562756, 0.22996172, 0.23280098, 0.24315893, 0.24583256, 0.2538079 , 0.25749268, 0.26467919, 0.26627951, 0.27002658, 0.283459 , 0.28441583, 0.2880536 , 0.28879776, 0.29773307, 0.30202578, 0.31152613, 0.32202995, 0.32461308, 0.37288269, 0.37416478, 0.37571831, 0.38134888, 0.39802175, 0.40161934, 0.40194454, 0.41445142, 0.41803173, 0.42351943, 0.43653428, 0.43966456, 0.44222414, 0.44497249, 0.44673657, 0.45125913, 0.454472 , 0.49209943, 0.49675952, 0.51355235, 0.51724753, 0.51807937, 0.52051719, 0.54412031, 0.55064775, 0.57135187, 0.59397426, 0.60096648, 0.61651659, 0.62057772, 0.62067109, 0.62629695, 0.62876413, 0.63856712, 0.64779433, 0.64818744, 0.65129871, 0.65202361, 0.65651101, 0.66092028, 0.66814002, 0.6711466 , 0.68434287, 0.68584875, 0.72771397, 0.74146852, 0.74838702, 0.75924582, 0.7599495 , 0.76223722, 0.76738866, 0.7746788 , 0.78006621, 0.79383978, 0.79696902, 0.83460266, 0.84990723, 0.86053885, 0.8636594 , 0.86565305, 0.87778554, 0.88858246, 0.89611668, 0.91026752, 0.91630374, 0.91699185, 0.92085513, 0.92233281, 0.92353131, 0.92638597, 0.92838719, 0.93261004, 0.94040085, 0.94326279])) .",
            "url": "https://yoseung.github.io/yosung/2022/05/08/%EA%B0%95%ED%9A%A8%EC%8A%B9.html",
            "relUrl": "/2022/05/08/%EA%B0%95%ED%9A%A8%EC%8A%B9.html",
            "date": " • May 8, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://yoseung.github.io/yosung/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://yoseung.github.io/yosung/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "스터디 . ’-‘ 머신러닝 . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://yoseung.github.io/yosung/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://yoseung.github.io/yosung/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}